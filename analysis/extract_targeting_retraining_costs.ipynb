{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/karolinegriesbach/Documents/Innkeepr/Git/consumption-based-costs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de372acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from src.utils.accounts import sanitize_account_name\n",
    "from src.utils.innkeepr_api import call_api_with_service_token, send_to_innkeepr_api_paginated\n",
    "from src.utils.constants import return_api_url_innkeepr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1efafa",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407901b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = \"2024-01-01\"\n",
    "to_date=\"2025-06-05\"\n",
    "timestamp = \"2025-06-05 19:48:58.031710\"\n",
    "path_to_dir = f\"/Users/karolinegriesbach/Documents/Innkeepr/Git/consumption-based-costs/data/{from_date}_to_{to_date}/{timestamp}/\"\n",
    "path_to_save = f\"/Users/karolinegriesbach/Documents/Innkeepr/Git/consumption-based-costs/data/{from_date}_to_{to_date}/targeting_and_retraining/\"\n",
    "path_to_data=f\"{path_to_dir}final_costs_with_azure_and_aws_and_db_{from_date}_{to_date}.csv\"\n",
    "url = return_api_url_innkeepr()\n",
    "stackit_cost_handling = {\n",
    "    \"start\": \"2024-11-11\",\n",
    "    \"exlude_date_ranges\": [\n",
    "        {\n",
    "            \"start\": \"2024-12-22\",\n",
    "            \"end\" : \"2025-01-03\",\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path_to_save, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb359e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303142c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "df = df[[col for col in df.columns if \"Unnamed\" not in col]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97355723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prefect_Deployments\"] = df[\"Prefect_Deployments\"].replace(\"retrainng\", \"retraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prefect_Deployments\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Deployments\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54048c17",
   "metadata": {},
   "source": [
    "# Filter Data\n",
    "Filter data for targeting runs only using Deployments and Prefect_Deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stackIT costs via Prefect_Deployments\n",
    "targeting_and_retraining_runs = df[(df[\"Deployments\"]==\"targeting\")|(df[\"Prefect_Deployments\"]==\"targeting\")|(df[\"Deployments\"]==\"retraining\")|(df[\"Prefect_Deployments\"]==\"retraining\")]\n",
    "# Bug in cost extractor: \"retrainng\" instead of \"retraining\" (behoben)\n",
    "targeting_and_retraining_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_and_retraining_runs[\"Prefect_Deployments\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1098d",
   "metadata": {},
   "source": [
    "# Historical count of targeting runs and prefect runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_runs = targeting_and_retraining_runs[targeting_and_retraining_runs[\"Prefect_Deployments\"]==\"targeting\"]\n",
    "retraining_runs = targeting_and_retraining_runs[targeting_and_retraining_runs[\"Prefect_Deployments\"]==\"retraining\"]\n",
    "runs_vc_by_date = targeting_runs.groupby(\"date\")[\"Prefect_Deployments\"].value_counts()\n",
    "runs_vc_by_date = pd.DataFrame(runs_vc_by_date).reset_index().rename(columns={\"count\":\"count targeting runs\"})\n",
    "runs_vc_by_date_retraining = retraining_runs.groupby(\"date\")[\"Prefect_Deployments\"].value_counts()\n",
    "runs_vc_by_date_retraining = pd.DataFrame(runs_vc_by_date_retraining).reset_index().rename(columns={\"count\":\"count retraining runs\"})\n",
    "audiences_unique_by_date = targeting_runs.groupby(\"date\")[\"audience_id\"].nunique()\n",
    "audiences_unique_by_date = pd.DataFrame(audiences_unique_by_date).reset_index()\n",
    "concat = pd.merge(runs_vc_by_date, audiences_unique_by_date, on=\"date\")\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"count targeting runs\",\n",
    "    data=runs_vc_by_date[runs_vc_by_date[\"date\"] > \"2025-01-01\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"# targeting runs\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"count retraining runs\",\n",
    "    data=runs_vc_by_date_retraining[runs_vc_by_date_retraining[\"date\"] > \"2025-01-01\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"# retraining runs\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"audience_id\",\n",
    "    data=audiences_unique_by_date[audiences_unique_by_date[\"date\"] > \"2025-01-01\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\":\",\n",
    "    label=\"unique audiences\"\n",
    ")\n",
    "plt.title(\"Count Daily targeting runs\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f02ba5",
   "metadata": {},
   "source": [
    "# Check Data Completion for node types, date and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(targeting_and_retraining_runs))\n",
    "null_values = targeting_and_retraining_runs[[\"node_name\",\"date\",\"charge\",\"machine.type\",\"audience_id\",\"duration\",\"total_charge_of_serviceName\",\"audience\"]].isnull().sum()\n",
    "null_values = pd.DataFrame(null_values).rename(columns={0:\"isnull\"})\n",
    "null_values[\"percentage_of_isnull\"] = null_values[\"isnull\"]/len(targeting_and_retraining_runs) * 100\n",
    "null_values.sort_values(by=\"isnull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5695777",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "- fehlend node_names mit existing node_names anreichern via targeting audience\n",
    "- fehlende Kosten über node_names und runtime anreichern\n",
    "- charges per targeting run erst ab dm 26.05.2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6193b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_and_retraining_runs[[\"Prefect_Deployments\",\"audience_id\",\"date\",\"charge\",\"node_name\",\"machine.type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size_mapping = targeting_and_retraining_runs.drop_duplicates(subset=[\"Prefect_Deployments\",\"audience_id\",\"node_name\",\"machine.type\"])[[\"Prefect_Deployments\",\"tenant\",\"audience_id\",\"node_name\",\"machine.type\"]]\n",
    "# check for audiences with several nodes\n",
    "vc_audience_nodes = node_size_mapping.groupby(\"audience_id\")[\"node_name\"].nunique()\n",
    "vc_audience_nodes_more_than_one = vc_audience_nodes[vc_audience_nodes>1]\n",
    "if vc_audience_nodes_more_than_one.empty == False:\n",
    "    print(f\"Several audiences have more than one node type: {len(vc_audience_nodes)}\")\n",
    "node_size_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f05d04",
   "metadata": {},
   "source": [
    "## Query models for all active accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926076e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query models to map audience node_name with targetingOutlook (is one of the main parameter to choose the node size)\n",
    "try:\n",
    "    models = pd.read_csv(f\"{path_to_save}all_models.csv\")\n",
    "    with open(f\"{path_to_save}ignore_tenants.json\", \"r\") as f:\n",
    "        ignore_tenants = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"query data\")\n",
    "    models=pd.DataFrame()\n",
    "    #min_date = targeting_and_retraining_runs[\"date\"].min()\n",
    "    #min_date = (pd.to_datetime(min_date)-timedelta(days=60)).strftime(\"%Y-%m-%d\")\n",
    "    ignore_tenants = []\n",
    "    accounts = call_api_with_service_token(f\"{url}/core/accounts/query\", {}, logging)\n",
    "    for tenant in targeting_and_retraining_runs[\"tenant\"].unique():\n",
    "        print(tenant)\n",
    "        account_id = [acc[\"id\"] for acc in accounts if sanitize_account_name(acc[\"name\"])==tenant]\n",
    "        if len(account_id) > 1:\n",
    "            raise Exception(f\"More than one account with name {tenant}\")\n",
    "        if len(account_id) == 0:\n",
    "            print(f\"Tenant {tenant} not found in accounts\")\n",
    "            ignore_tenants.append(tenant)\n",
    "            continue\n",
    "        account_id = account_id[0]\n",
    "        temp_models = send_to_innkeepr_api_paginated(\n",
    "            f\"{url}/models/query\",\n",
    "            account_id,\n",
    "            {},\n",
    "            logging\n",
    "        )\n",
    "        temp_models = pd.json_normalize(temp_models)\n",
    "        if len(temp_models) == 0:\n",
    "            print(f\"No models found for tenant {tenant}\")\n",
    "            ignore_tenants.append(tenant)\n",
    "            continue\n",
    "        #temp_models = temp_models[temp_models[\"created\"]>=min_date]\n",
    "        models = pd.concat([models, temp_models])\n",
    "    print(models.shape)\n",
    "    missing_audiences = targeting_runs[targeting_runs[\"tenant\"].isin(ignore_tenants)==False]\n",
    "    missing_audiences = missing_audiences[missing_audiences[\"audience_id\"].isin(models[\"audience\"].unique())==False]\n",
    "    if missing_audiences.empty == False:\n",
    "        print(f\"Missing {len(missing_audiences)} models\")\n",
    "        print(missing_audiences[[\"tenant\",\"audience_id\"]].drop_duplicates())\n",
    "    models.to_csv(f\"{path_to_save}all_models.csv\")\n",
    "    with open(f\"{path_to_save}ignore_tenants.json\", \"w\") as f:\n",
    "        json.dump(list(ignore_tenants), f)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d759b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiences_in_models_but_not_in_targeting_runs = models[\n",
    "    (models[\"audience\"].isin(targeting_runs[targeting_runs[\"tenant\"].isin(ignore_tenants)==False][\"audience_id\"].unique())==False) &\n",
    "    (models[\"created\"]>=targeting_runs[\"date\"].min())\n",
    "    ]\n",
    "if audiences_in_models_but_not_in_targeting_runs.empty == False:\n",
    "    print(f\"Found {len(audiences_in_models_but_not_in_targeting_runs)} models that are not in the targeting runs\")\n",
    "    raise Exception(audiences_in_models_but_not_in_targeting_runs[[\"audience\",\"path\",\"created\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d62248",
   "metadata": {},
   "source": [
    "## Merge Models and Targeting Runs by considering date and targetingOutlookDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4297c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models[[\"audience\",\"created\",\"targetingOutlookDays\"]]\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_and_retraining_runs[\"tenant\"] = np.where(\n",
    "    targeting_and_retraining_runs[\"tenant\"].isnull(),\n",
    "    targeting_and_retraining_runs[\"account\"].str.replace(\" \",\"\").str.lower(),\n",
    "    targeting_and_retraining_runs[\"tenant\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models.rename(columns={\"audience\":\"audience_id\",\"created\":\"created_data_model_for_testing\"})\n",
    "# Filter data_model_for_testing to get the most recent model for each audience before the date in data_for_testing\n",
    "print(f\"targeting_and_retraining_runs = {len(targeting_and_retraining_runs)}\")\n",
    "merged_targeting_runs_with_models = pd.merge(targeting_and_retraining_runs, models, on=['audience_id'], how=\"left\")#suffixes=('_data_for_testing', '_data_model_for_testing'))\n",
    "# macht data where the model.created < data.timestamp\n",
    "merged_targeting_runs_with_models_with_previous_models = merged_targeting_runs_with_models[pd.to_datetime(merged_targeting_runs_with_models['created_data_model_for_testing'],utc=True) <= pd.to_datetime(merged_targeting_runs_with_models['timestamp'],utc=True)]\n",
    "merged_targeting_runs_with_models_with_previous_models = merged_targeting_runs_with_models_with_previous_models.sort_values(by='created_data_model_for_testing', ascending=False).drop_duplicates(subset=['Prefect_Deployments','tenant','audience_id','timestamp','node_name'], keep='first')\n",
    "print(f\"merged_targeting_runs_with_models_with_previous_models = {len(merged_targeting_runs_with_models_with_previous_models)}\")\n",
    "# get data where data.timestamp does not have a matching model\n",
    "merged_targeting_runs_with_models_without_previous_models = models.groupby(\"audience_id\")[\"created_data_model_for_testing\"].min()\n",
    "merged_targeting_runs_with_models_without_previous_models = pd.DataFrame(merged_targeting_runs_with_models_without_previous_models).reset_index()\n",
    "merged_targeting_runs_with_models_without_previous_models = pd.merge(targeting_and_retraining_runs, merged_targeting_runs_with_models_without_previous_models, on=\"audience_id\")\n",
    "merged_targeting_runs_with_models_without_previous_models = merged_targeting_runs_with_models_without_previous_models[pd.to_datetime(merged_targeting_runs_with_models_without_previous_models['timestamp'],utc=True) <= pd.to_datetime(merged_targeting_runs_with_models_without_previous_models['created_data_model_for_testing'],utc=True)]\n",
    "print(f\"merged_targeting_runs_with_models_without_previous_models = {len(merged_targeting_runs_with_models_without_previous_models)}\")\n",
    "# get data with null models\n",
    "considered_audiences = merged_targeting_runs_with_models_with_previous_models[\"audience_id\"].unique().tolist() + merged_targeting_runs_with_models_without_previous_models[\"audience_id\"].unique().tolist()\n",
    "merged_targeting_runs_with_models_null_models = merged_targeting_runs_with_models[\n",
    "    (merged_targeting_runs_with_models[\"audience_id\"].isin(considered_audiences) == False)]\n",
    "merged_targeting_runs_with_models_null_models = merged_targeting_runs_with_models_null_models[merged_targeting_runs_with_models_null_models[\"tenant\"].isin(ignore_tenants)==False]\n",
    "print(f\"merged_targeting_runs_with_models_null_models = {len(merged_targeting_runs_with_models_null_models)}\")\n",
    "# concate data\n",
    "merged_targeting_runs_with_models = pd.concat([merged_targeting_runs_with_models_with_previous_models, merged_targeting_runs_with_models_without_previous_models,merged_targeting_runs_with_models_null_models])\n",
    "merged_targeting_runs_with_models = merged_targeting_runs_with_models.reset_index(drop=True)\n",
    "print(f\"merged_targeting_runs_with_models = {len(merged_targeting_runs_with_models)}\")\n",
    "targeting_runs_to_compare = targeting_and_retraining_runs[targeting_and_retraining_runs[\"tenant\"].isin(ignore_tenants)==False]\n",
    "if len(merged_targeting_runs_with_models) != len(targeting_runs_to_compare):\n",
    "    raise Exception(f\"Unequal length targeting_runs_to_compare {len(targeting_runs_to_compare)} vs. merged {len(merged_targeting_runs_with_models)}\")\n",
    "merged_targeting_runs_with_models[[\"tenant\",\"audience_id\",\"date\",\"node_name\",\"timestamp\",\"created_data_model_for_testing\",\"targetingOutlookDays\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataframe does not match lenght - check why\n",
    "vc_before = pd.DataFrame(targeting_and_retraining_runs[targeting_and_retraining_runs[\"tenant\"].isin(ignore_tenants)==False].groupby(by=[\"Prefect_Deployments\",\"audience_id\"])[\"date\"].value_counts()).reset_index().sort_values(by=[\"audience_id\",\"date\"], ascending=False).reset_index(drop=True)\n",
    "vc_after = pd.DataFrame(merged_targeting_runs_with_models.groupby(by=[\"Prefect_Deployments\",\"audience_id\"])[\"date\"].value_counts()).reset_index().sort_values(by=[\"audience_id\",\"date\"], ascending=False).reset_index(drop=True)\n",
    "if vc_after.equals(vc_before):\n",
    "    print(\"fine\")\n",
    "else:\n",
    "    print(\"not fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bbc70",
   "metadata": {},
   "source": [
    "# Extract node gb size and cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8789671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_parameters(string,node_spec=None):\n",
    "    #print(string)\n",
    "    if isinstance(string, str) == False:\n",
    "        #print(f\"String is not given\")\n",
    "        return None\n",
    "    if \"medium32g\" in string:\n",
    "        if node_spec == \"cpu\":\n",
    "            return None\n",
    "        elif node_spec == \"gb\":\n",
    "            return 32\n",
    "        else:\n",
    "            raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    if \"x2large\" in string:\n",
    "        if node_spec == \"cpu\":\n",
    "            return 29\n",
    "        elif node_spec == \"gb\":\n",
    "            return 350\n",
    "        else:\n",
    "            raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    if \"small\" in string:\n",
    "        if node_spec == \"cpu\":\n",
    "            return 3\n",
    "        elif node_spec == \"gb\":\n",
    "            return 4\n",
    "        else:\n",
    "            raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    if \"xlarge\" in string:\n",
    "        if node_spec == \"cpu\":\n",
    "            return 7\n",
    "        elif node_spec == \"gb\":\n",
    "            return 110\n",
    "        else:\n",
    "            raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    if \"medium64g\" in string:\n",
    "        if node_spec == \"cpu\":\n",
    "            return 3\n",
    "        elif node_spec == \"gb\":\n",
    "            return 55\n",
    "        else:\n",
    "            raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    # match the string for cpu and gb\n",
    "    match = re.search(r\"(\\d+)cpu(\\d+)gib\", string)\n",
    "    if match is False:\n",
    "        print(f\"No match found for {string}\")\n",
    "        return None\n",
    "    elif node_spec is None:\n",
    "        raise ValueError(f\"Node spec needs to be cpu or gb\")\n",
    "    elif node_spec == \"cpu\":\n",
    "        return int(match.group(1))\n",
    "    elif node_spec == \"gb\":\n",
    "        return int(match.group(2))\n",
    "    else:\n",
    "        raise ValueError(f\"Node spec needs to be cpu or gb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targeting_runs_with_models[\"node_gb\"] = merged_targeting_runs_with_models[\"node_name\"].apply(lambda x: extract_node_parameters(x,node_spec=\"gb\"))\n",
    "merged_targeting_runs_with_models[\"node_cpu\"] = merged_targeting_runs_with_models[\"node_name\"].apply(lambda x: extract_node_parameters(x,node_spec=\"cpu\"))\n",
    "merged_targeting_runs_with_models[[\"tenant\",\"audience_id\",\"node_name\",\"timestamp\",\"targetingOutlookDays\",\"node_gb\",\"node_cpu\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac5aa4",
   "metadata": {},
   "source": [
    "## Add missing node sizes via current node size mapping\n",
    "- needs a long time (to speed it up - get audiences with one specification and just iterate over audiences with several specifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size_mapping_with_size = merged_targeting_runs_with_models.dropna(subset=[\"node_name\"]).drop_duplicates(subset=[\"audience_id\",\"node_name\",\"targetingOutlookDays\",\"node_gb\",\"node_cpu\"])[[\"tenant\",\"audience_id\",\"node_name\",\"node_gb\",\"node_cpu\",\"targetingOutlookDays\"]]\n",
    "vc = pd.DataFrame(node_size_mapping_with_size.groupby(\"audience_id\")[\"node_name\"].nunique()).rename(columns={\"node_name\":\"node_count\"})\n",
    "node_size_mapping_with_size = pd.merge(node_size_mapping_with_size, vc, on=\"audience_id\", how=\"left\")\n",
    "vc_max = merged_targeting_runs_with_models.groupby(by=[\"audience_id\",\"node_name\",\"targetingOutlookDays\",\"node_gb\",\"node_cpu\"])[\"timestamp\"].max().reset_index()\n",
    "node_size_mapping_with_size = pd.merge(node_size_mapping_with_size, vc_max, on=[\"audience_id\",\"node_name\",\"targetingOutlookDays\",\"node_gb\",\"node_cpu\"], how=\"left\")\n",
    "for col in node_size_mapping_with_size.columns:\n",
    "    node_size_mapping_with_size = node_size_mapping_with_size.rename(columns={col: f\"{col}_nm\"})\n",
    "node_size_mapping_with_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targeting_runs_with_models_with_node_size = pd.merge(\n",
    "    merged_targeting_runs_with_models,\n",
    "    node_size_mapping_with_size,\n",
    "    left_on=[\"tenant\",\"targetingOutlookDays\"],\n",
    "    right_on = [\"tenant_nm\",\"targetingOutlookDays_nm\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "merged_targeting_runs_with_models_with_node_size[[\"tenant\",\"timestamp\",\"audience_id\",\"targetingOutlookDays\",\"node_name\",\"node_gb\",\"node_cpu\"]+node_size_mapping_with_size.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targeting_runs_with_models_with_node_size = merged_targeting_runs_with_models_with_node_size.sort_values(by=[\"tenant\",\"audience_id\",\"timestamp\",\"node_gb_nm\"]).drop_duplicates(subset=[\"tenant\",\"audience_id\",\"timestamp\"],keep=\"last\")\n",
    "merged_targeting_runs_with_models_with_node_size[\"merged_node_name\"] = np.where(\n",
    "    merged_targeting_runs_with_models_with_node_size[\"node_name\"].isnull(),\n",
    "    merged_targeting_runs_with_models_with_node_size[\"node_name_nm\"],\n",
    "    merged_targeting_runs_with_models_with_node_size[\"node_name\"]\n",
    ")\n",
    "merged_targeting_runs_with_models_with_node_size[[\"tenant\",\"timestamp\",\"audience_id\",\"timestamp\",\"targetingOutlookDays\",\"node_name\",\"node_gb_nm\",\"merged_node_name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c76cf0",
   "metadata": {},
   "source": [
    "## Check Data Quality of Node Size Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046385aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_node_size_mapping = merged_targeting_runs_with_models_with_node_size[merged_targeting_runs_with_models_with_node_size[\"merged_node_name\"].isnull()].drop_duplicates(subset=[\"tenant\",\"targetingOutlookDays\"])\n",
    "null_node_size_mapping[[\"tenant\",\"targetingOutlookDays\",\"date\"]]\n",
    "print(f\"Found {len(null_node_size_mapping)} null node size mappings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_node_size_mapping[[\"tenant\",\"targetingOutlookDays\",\"node_name\",\"audience_id\",\"date\"]]#.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83485a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targeting_runs_with_models_with_node_size.to_csv(f\"{path_to_save}merged_targeting_runs_with_models_with_node_size.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3725472",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targeting_runs_with_models_with_node_size[[\"tenant\",\"timestamp\",\"audience_id\",\"merged_node_name\",\"duration\",\"charge\",\"part_of_costs\",\"total_charge_of_serviceName\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba35da0",
   "metadata": {},
   "source": [
    "# Extract Valid Time Window for Calculating Costs\n",
    "- erstmal nur StackIT-Kosten berücksichtigen\n",
    "- StackIT 03.11 - 10.11: sehr viele Testruns\n",
    "- stackIT start date: 11.11.2025 (Umzug)\n",
    "- Zeiträume, wo azure lief (erstmal außen vor lassen): 2024-12-22 & 2025-01-03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147aaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackit_cost_handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47815c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = merged_targeting_runs_with_models_with_node_size[merged_targeting_runs_with_models_with_node_size[\"date\"]>= stackit_cost_handling[\"start\"]]\n",
    "print(f\"Min to max date in df_cleaned: {df_cleaned['date'].min()} to {df_cleaned['date'].max()}\")\n",
    "for exlcude_dates in stackit_cost_handling[\"exlude_date_ranges\"]:\n",
    "    print(f\"Excluding date range: {exlcude_dates['start']} to {exlcude_dates['end']}\")\n",
    "    idx_to_remove = df_cleaned[\n",
    "        (df_cleaned[\"date\"] >= exlcude_dates[\"start\"]) & (df_cleaned[\"date\"] <= exlcude_dates[\"end\"])\n",
    "    ].index\n",
    "    df_cleaned = df_cleaned.drop(idx_to_remove)\n",
    "df_cleaned=df_cleaned.reset_index(drop=True)\n",
    "df_cleaned[\"date\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[[\"Prefect_Deployments\",\"tenant\",\"audience_id\",\"date\",\"node_name\",\"merged_node_name\",\"charge\",\"part_of_costs\",\"total_charge_of_serviceName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"merged_node_name\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_node_names = df_cleaned[df_cleaned[\"merged_node_name\"].isin([\"medium32g\", \"medium64g\", \"small\", \"x2large\", \"xlarge\", \"nan\"])]\n",
    "azure_node_names[[\"Prefect_Deployments\",\"tenant\",\"audience_id\",\"date\",\"node_name\",\"merged_node_name\",\"machine.type\",\"charge\",\"part_of_costs\",\"total_charge_of_serviceName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451576da",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df[\"tenant\"]==\"ective\"]\n",
    "temp = df[df[\"Prefect_Deployments\"]==\"retraining\"]\n",
    "#temp = df[df[\"audience_id\"]==\"654199d5c55281d53441fdf2\"]\n",
    "#/Users/karolinegriesbach/Documents/Innkeepr/Git/consumption-based-costs/data/2024-01-01_to_2025-06-05/2025-06-05 19:48:58.031710/prefect_data_2024-01-01_2025-06-05_databricks_prefect_logs.csv -> somewhere here wrong node size matching\n",
    "temp[[\"Prefect_Deployments\",\"tenant\",\"audience_id\",\"date\",\"node_name\",\"machine.type\",\"charge\",\"part_of_costs\",\"total_charge_of_serviceName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nodes_by_customer = pd.DataFrame(df_cleaned.groupby(by=[\"date\",\"tenant\",\"Prefect_Deployments\"])[\"merged_node_name\"].unique()).reset_index()\n",
    "count_nodes_by_customer.sort_values(by=[\"tenant\",\"date\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_null = df_cleaned[df_cleaned[\"total_charge_of_serviceName\"].isnull()]\n",
    "print(charge_null[\"date\"].min(), charge_null[\"date\"].max(), len(charge_null))\n",
    "vc_charge_null = pd.DataFrame(charge_null[\"date\"].value_counts().sort_index()).rename(columns={\"count\":\"count_charge_null\"})\n",
    "vc_charge_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e70fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_not_null = df_cleaned[df_cleaned[\"total_charge_of_serviceName\"].notnull()]\n",
    "charge_not_null[\"date\"].min(), charge_not_null[\"date\"].max(), len(charge_not_null)\n",
    "vc_charge_not_null = pd.DataFrame(charge_not_null[\"date\"].value_counts().sort_index()).rename(columns={\"count\":\"count_charge_not_null\"})\n",
    "vc_charge_not_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_charge_counts = pd.merge(vc_charge_null, vc_charge_not_null, on=\"date\", how=\"outer\").sort_values(by=\"date\")\n",
    "vc_charge_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbf406",
   "metadata": {},
   "source": [
    "# Get targeting costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b2b3e",
   "metadata": {},
   "source": [
    "# Playaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3228e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_testing = targeting_runs[targeting_runs[\"tenant\"]==\"pendix\"]\n",
    "data_for_testing = data_for_testing[data_for_testing[\"date\"]>=\"2025-04-01\"].sort_values(by=[\"audience_id\",\"date\"], ascending=False)\n",
    "data_for_testing[[\"tenant\",\"audience_id\",\"date\",\"node_name\",\"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_for_testing = models[models[\"audience\"].isin(data_for_testing[\"audience_id\"].unique())]\n",
    "data_model_for_testing=data_model_for_testing[data_model_for_testing[\"created\"]>=\"2025-03-01\"].sort_values(by=[\"audience\",\"created\"], ascending=False)\n",
    "data_model_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd80c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_for_testing = data_model_for_testing.rename(columns={\"audience\":\"audience_id\",\"created\":\"created_data_model_for_testing\"})\n",
    "# Filter data_model_for_testing to get the most recent model for each audience before the date in data_for_testing\n",
    "merged_data = pd.merge(data_for_testing, data_model_for_testing, on='audience_id', suffixes=('_data_for_testing', '_data_model_for_testing'))\n",
    "merged_data = merged_data[merged_data['created_data_model_for_testing'] < merged_data['date']]\n",
    "merged_data = merged_data.sort_values(by='created_data_model_for_testing', ascending=False).drop_duplicates(subset=['tenant','audience_id','timestamp','node_name'], keep='first')\n",
    "merged_data[[\"tenant\",\"audience_id\",\"date\",\"node_name\",\"timestamp\",\"created_data_model_for_testing\",\"targetingOutlookDays\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca40191",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_before = pd.DataFrame(data_for_testing.groupby(\"audience_id\")[\"date\"].value_counts()).reset_index().sort_values(by=[\"audience_id\",\"date\"], ascending=False)\n",
    "vc_after = pd.DataFrame(merged_data.groupby(\"audience_id\")[\"date\"].value_counts()).reset_index().sort_values(by=[\"audience_id\",\"date\"], ascending=False)\n",
    "if vc_after.equals(vc_before):\n",
    "    print(\"fine\")\n",
    "else:\n",
    "    print(\"not fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3880750",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data_for_testing) != len(merged_data):\n",
    "    raise Exception(\"len(data_for_testing) != len(merged_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef3394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "consumption-based-costs-wGvc2ut4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
